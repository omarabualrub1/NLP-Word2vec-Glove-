{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Libraries**"
      ],
      "metadata": {
        "id": "5NjiMH6REOeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "T2nvsaXcEgLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load word2vec and glove**"
      ],
      "metadata": {
        "id": "SuBA8GpLEg1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def Dow2v():\n",
        "    print(\"Downloading Word2Vec model...\")\n",
        "    word2vec_path = \"GoogleNews-vectors-negative300.bin\"\n",
        "    if not os.path.exists(word2vec_path):\n",
        "        word2vec = api.load(\"word2vec-google-news-300\")\n",
        "        word2vec.save_word2vec_format(word2vec_path, binary=True)\n",
        "    return KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
        "\n",
        "def Dowglv():\n",
        "    print(\"Downloading GloVe embeddings...\")\n",
        "    glove_zip_path = \"glove.6B.zip\"\n",
        "    glove_txt_path = \"glove.6B.300d.txt\"\n",
        "    if not os.path.exists(glove_txt_path):\n",
        "        url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "        response = requests.get(url)\n",
        "        with open(glove_zip_path, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "        with zipfile.ZipFile(glove_zip_path, \"r\") as zip_ref:\n",
        "            zip_ref.extractall()\n",
        "    return loadglv(glove_txt_path)\n",
        "\n",
        "def loadglv(glove_file_path):\n",
        "    glove_model = {}\n",
        "    with open(glove_file_path, encoding=\"utf8\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            word = parts[0]\n",
        "            vector = np.array(parts[1:], dtype=np.float32)\n",
        "            glove_model[word] = vector\n",
        "    return glove_model\n",
        "\n",
        "word2vec = Dow2v()\n",
        "glove = Dowglv()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A02_FtAVEtos",
        "outputId": "eaac8e5a-c0be-4a2e-e2e0-479b35267176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Word2Vec model...\n",
            "Downloading GloVe embeddings...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cosine Similarity**"
      ],
      "metadata": {
        "id": "y3uUG3AfEvnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cossim(vec1, vec2):\n",
        "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
      ],
      "metadata": {
        "id": "CHyPfvDPEwM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Find Analogy**"
      ],
      "metadata": {
        "id": "IlwG4NDcF-up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def findglvanalogy(glove_model, word_a, word_b, word_c, top_n=1):\n",
        "    if word_a not in glove_model or word_b not in glove_model or word_c not in glove_model:\n",
        "        print(f\"[GloVe] Missing one or more words: '{word_a}', '{word_b}', '{word_c}'\")\n",
        "        return None\n",
        "\n",
        "    vec_a = glove_model[word_a]\n",
        "    vec_b = glove_model[word_b]\n",
        "    vec_c = glove_model[word_c]\n",
        "\n",
        "    target_vector = vec_b - vec_a + vec_c\n",
        "\n",
        "    similarities = []\n",
        "    for word in glove_model:\n",
        "        if word in [word_a, word_b, word_c]:\n",
        "            continue\n",
        "        similarity = cossim(target_vector, glove_model[word])\n",
        "        similarities.append((word, similarity))\n",
        "\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "    return [word for word, _ in similarities[:top_n]]\n"
      ],
      "metadata": {
        "id": "EmhSgOdWEyVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findw2vanalogy(model, word_a, word_b, word_c, top_n=1):\n",
        "    if word_a not in model.key_to_index or word_b not in model.key_to_index or word_c not in model.key_to_index:\n",
        "        print(f\"[Word2Vec] Missing one or more words: '{word_a}', '{word_b}', '{word_c}'\")\n",
        "        return None\n",
        "\n",
        "    vec_a = model[word_a]\n",
        "    vec_b = model[word_b]\n",
        "    vec_c = model[word_c]\n",
        "    target_vector = vec_b - vec_a + vec_c\n",
        "\n",
        "    results = model.similar_by_vector(target_vector, topn=top_n+3)\n",
        "\n",
        "    output = []\n",
        "    for word, score in results:\n",
        "        if word not in [word_a, word_b, word_c]:\n",
        "            output.append(word)\n",
        "            if len(output) >= top_n:\n",
        "                break\n",
        "    return output[:top_n]"
      ],
      "metadata": {
        "id": "syM53nCCEzeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluate Analogy**"
      ],
      "metadata": {
        "id": "yjEanUaUGLTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evalanalogy(tests, model, model_name, is_glove=False):\n",
        "    results = []\n",
        "    for i, (a, b, c, expected) in enumerate(tests, 1):\n",
        "        try:\n",
        "            if not is_glove:\n",
        "                a, b, c = a.lower(), b.lower(), c.lower()\n",
        "                expected = expected.lower()\n",
        "\n",
        "            if is_glove:\n",
        "                result = findglvanalogy(model, a, b, c)\n",
        "            else:\n",
        "                result = findw2vanalogy(model, a, b, c)\n",
        "            prediction = result[0] if result else \"N/A\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error in test {i}: {e}\")\n",
        "            prediction = \"N/A\"\n",
        "        results.append([i, f\"{a} : {b} :: {c} : ?\", expected, prediction])\n",
        "    return pd.DataFrame(results, columns=[\"Test #\", \"Test\", \"Expected\", f\"{model_name} Result\"])\n"
      ],
      "metadata": {
        "id": "-fasXaTLE02S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Semantic & Syntactic Words**"
      ],
      "metadata": {
        "id": "qyye3EWcGUsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "semanticTests = [\n",
        "    (\"brother\", \"sister\", \"uncle\", \"aunt\"),\n",
        "    (\"roma\", \"italy\", \"barcelona\", \"spain\"),\n",
        "    (\"madrid\", \"spain\", \"berlin\", \"germany\"),\n",
        "    (\"king\", \"queen\", \"emperor\", \"empress\"),\n",
        "    (\"cat\", \"kitten\", \"dog\", \"puppy\"),\n",
        "    (\"eyes\", \"see\", \"ears\", \"hear\"),\n",
        "    (\"cow\", \"milk\", \"bee\", \"honey\"),\n",
        "    (\"yale\", \"college\",\"harvard\", \"university\"),\n",
        "    (\"morning\", \"breakfast\", \"evening\", \"dinner\"),\n",
        "    (\"money\", \"coin\", \"gold\", \"silver\")\n",
        "]\n",
        "\n",
        "syntacticTests = [\n",
        "    (\"tiny\", \"tinier\",\"loud\", \"louder\"),\n",
        "    ('blink', 'blinking', 'sleep', 'sleeping'),\n",
        "    (\"quick\", \"quickly\", \"slow\", \"slowly\"),\n",
        "    (\"zoom\", \"zooming\", \"bounce\", \"bouncing\"),\n",
        "    (\"clean\", \"cleaner\", \"dirty\", \"dirtier\"),\n",
        "    (\"rich\", \"richer\", \"poor\", \"poorer\"),\n",
        "    (\"sit\", \"sat\", \"stand\", \"stood\"),\n",
        "    (\"break\", \"broken\", \"take\", \"taken\"),\n",
        "    (\"cook\", \"cooking\", \"bake\", \"baking\"),\n",
        "    (\"give\", \"gave\", \"receive\", \"received\")\n",
        "]"
      ],
      "metadata": {
        "id": "QwPUy37oE2H8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Results**"
      ],
      "metadata": {
        "id": "7kqltrlTGjZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "semanticglv = evalanalogy(semanticTests, glove, \"GloVe\", is_glove=True)\n",
        "syntacticglv = evalanalogy(syntacticTests, glove, \"GloVe\", is_glove=True)\n",
        "\n",
        "semanticw2v = evalanalogy(semanticTests, word2vec, \"Word2Vec\", is_glove=False)\n",
        "syntacticw2v = evalanalogy(syntacticTests, word2vec, \"Word2Vec\", is_glove=False)\n",
        "\n",
        "semantic = semanticglv.copy()\n",
        "semantic[\"Word2Vec Result\"] = semanticw2v[\"Word2Vec Result\"]\n",
        "\n",
        "syntactic = syntacticglv.copy()\n",
        "syntactic[\"Word2Vec Result\"] = syntacticw2v[\"Word2Vec Result\"]\n",
        "\n",
        "print(\"\\nResult (Semantic Analogies):\")\n",
        "print(semantic.to_string(index=False))\n",
        "\n",
        "print(\"\\nResult (Syntactic Analogies):\")\n",
        "print(syntactic.to_string(index=False))"
      ],
      "metadata": {
        "id": "byKSLlEuE3Yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1273c7d-0cdc-4938-c8a7-d54e91a12c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Result (Semantic Analogies):\n",
            " Test #                               Test   Expected GloVe Result Word2Vec Result\n",
            "      1      brother : sister :: uncle : ?       aunt         aunt            aunt\n",
            "      2      roma : italy :: barcelona : ?      spain        spain           spain\n",
            "      3       madrid : spain :: berlin : ?    germany      germany         germany\n",
            "      4        king : queen :: emperor : ?    empress      empress         empress\n",
            "      5            cat : kitten :: dog : ?      puppy        puppy           puppy\n",
            "      6             eyes : see :: ears : ?       hear         hear            hear\n",
            "      7              cow : milk :: bee : ?      honey        honey           honey\n",
            "      8      yale : college :: harvard : ? university   university      university\n",
            "      9 morning : breakfast :: evening : ?     dinner       dinner          dinner\n",
            "     10           money : coin :: gold : ?     silver       silver          silver\n",
            "\n",
            "Result (Syntactic Analogies):\n",
            " Test #                          Test Expected GloVe Result Word2Vec Result\n",
            "      1     tiny : tinier :: loud : ?   louder       louder          louder\n",
            "      2 blink : blinking :: sleep : ? sleeping     sleeping        sleeping\n",
            "      3   quick : quickly :: slow : ?   slowly       slowly          slowly\n",
            "      4  zoom : zooming :: bounce : ? bouncing     bouncing        bouncing\n",
            "      5  clean : cleaner :: dirty : ?  dirtier      dirtier         dirtier\n",
            "      6     rich : richer :: poor : ?   poorer       poorer          poorer\n",
            "      7        sit : sat :: stand : ?    stood        stood           stood\n",
            "      8    break : broken :: take : ?    taken        taken           taken\n",
            "      9    cook : cooking :: bake : ?   baking       baking          baking\n",
            "     10    give : gave :: receive : ? received     received        received\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Accuracy**"
      ],
      "metadata": {
        "id": "RuI_I_xDGm8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(results_df, expected_col='Expected', predicted_col='Result'):\n",
        "    correct = 0\n",
        "    for expected, predicted in zip(results_df[expected_col], results_df[predicted_col]):\n",
        "        if str(predicted).lower() == str(expected).lower():\n",
        "            correct += 1\n",
        "    return (correct / len(results_df)) * 100\n",
        "\n",
        "semanticglvacc = accuracy(semanticglv, 'Expected', 'GloVe Result')\n",
        "semanticw2vacc = accuracy(semanticw2v, 'Expected', 'Word2Vec Result')\n",
        "syntacticglvacc = accuracy(syntacticglv, 'Expected', 'GloVe Result')\n",
        "syntacticw2vacc = accuracy(syntacticw2v, 'Expected', 'Word2Vec Result')\n",
        "\n",
        "summary_data = [\n",
        "    [\"Semantic\", f\"{semanticglvacc:.1f}%\", f\"{semanticw2vacc:.1f}%\"],\n",
        "    [\"Syntactic\", f\"{syntacticglvacc:.1f}%\", f\"{syntacticw2vacc:.1f}%\"]\n",
        "]\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data, columns=[\"Analogy Type\", \"GloVe Accuracy\", \"Word2Vec Accuracy\"])\n",
        "\n",
        "print(\"\\n\\nAccuracy:\")\n",
        "print(summary_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "YpP9b2_pE4jh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b73be0f-20fc-4798-917e-6d943332b6c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Accuracy:\n",
            "Analogy Type GloVe Accuracy Word2Vec Accuracy\n",
            "    Semantic         100.0%            100.0%\n",
            "   Syntactic         100.0%            100.0%\n"
          ]
        }
      ]
    }
  ]
}